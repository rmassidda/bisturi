{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b05b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabdc828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisturi.dataset.broden import BrodenDataset\n",
    "from bisturi.dataset.broden import BrodenOntology\n",
    "from random import choices\n",
    "import os\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.transforms import Resize\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, HBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_path = os.path.join(basepath, 'datasets/broden1_224/')\n",
    "ontology = BrodenOntology(dset_path)\n",
    "dset = BrodenDataset(dset_path, mean=[1,1,1], std=[1,1,1], ontology=ontology)\n",
    "concepts = ontology.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b6324a",
   "metadata": {},
   "source": [
    "## Aligned concepts\n",
    "\n",
    "We are interested in selecting the Wordnet Concepts which are directly aligned to Broden labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da29f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = ontology.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c0a8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_concepts = [c for c in concepts if c.original_b_ids]\n",
    "propagated = [c for c in concepts if c.propagated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf2b21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(aligned_concepts), len(propagated), len(concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8074b9",
   "metadata": {},
   "source": [
    "## Analyze WordNet Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d3384a-83b4-4b1a-b504-2af23484c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_idx = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa30538-4e62-4aad-96d1-6408c6fce3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = aligned_concepts[concept_idx]\n",
    "b_ids = iter(c.original_b_ids)\n",
    "\n",
    "\n",
    "print('IDX:', concept_idx, end='\\n\\n')\n",
    "print('Name:', c.synset.name(), 'n' + str(c.id)[1:], end='\\n\\n')\n",
    "print('Definition:', c.synset.definition(), sep='\\n', end='\\n\\n')\n",
    "print('Examples:', *c.synset.examples(), sep='\\n',end='\\n\\n')\n",
    "\n",
    "print('Hypernyms:', *c.synset.hypernyms(), sep='\\n',end='\\n\\n')\n",
    "\n",
    "try:\n",
    "    print('Hyponyms:', *choices(c.synset.hyponyms(), k=10), sep='\\n',end='\\n\\n')\n",
    "except IndexError:\n",
    "    print('No hyponyms', end='\\n\\n')\n",
    "\n",
    "print('Corresponding Broden:')\n",
    "for broden_id in c.original_b_ids:\n",
    "    print(broden_id, dset.labels[broden_id]['name'], dset.labels[broden_id]['syns'], sep='\\t')\n",
    "    \n",
    "    \n",
    "print('\\nSamples:')\n",
    "samples = dset.reverse_index[c.id]\n",
    "print(len(samples),'images found.\\n')\n",
    "samples = choices(samples, k=10)\n",
    "\n",
    "for sample in samples:\n",
    "    _, img, masks = dset[sample]\n",
    "\n",
    "    # Image\n",
    "    to_pil = ToPILImage()\n",
    "    original = to_pil(img)\n",
    "\n",
    "    # Mask\n",
    "    c_mask = masks.get_concept_mask(c)\n",
    "    if img.shape[1:] == c_mask.shape:\n",
    "        masked = img * c_mask\n",
    "    else:\n",
    "        to_cmask_size = Resize(c_mask.shape)\n",
    "        to_img_size = Resize(img.shape[1:])\n",
    "        masked = to_cmask_size(img)\n",
    "        masked = masked * c_mask\n",
    "        masked = to_img_size(masked)\n",
    "    masked = to_pil(masked)\n",
    "\n",
    "    display(original)\n",
    "    display(masked)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
